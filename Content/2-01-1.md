### Algorithms and mathematical models

This section provides example cases of "algorithmic bias" in welfare services that are in part computerised. Interestingly, it doesn't mention China's [Social Credit System](https://www.wired.co.uk/article/chinese-government-social-credit-score-privacy-invasion) which "rates" individuals according to trustworthiness: participation in the system became mandatory this year for Chinese citizens. Social Credit is economic and social reputation of individuals and business entities. Reputation is earned and lost by behaviours: good acts like giving blood or doing voluntary work are positive, bad acts like jaywalking, using your sister's transit ID card, jumping a red light, are negative. Credit determines how accessible services and rights are to you: university places, hospital procedures, employment, and so on. Untrustworthy citizens are posted on social media channels and posters.

#### Automating poverty task

Time is very short this week, so I skimmed the articles but did not participate in the crowdsourcing discussions[^yawn].

[^yawn]: I always find these a chore, and of little value in online courses like this. It's become a formula for the MOOC: I enjoyed these once, and have even gone on to connect in real life with people I've met in the discussion spaces. However, in the spaces where this has been trotted out as some kind of lazy self-service pedagogical device, it always falls flat as an empty task. I get nothing from these, and almost never get commentary on my contributions, including this course so far, in which there are a number of people talking in threads, but not to each other. Pearls before swine, darling.

