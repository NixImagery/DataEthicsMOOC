## Introduction to Ethics

Issues arising from the 2018 Cambridge Analaytica scandal are identified as:

* the value derived from data is not evenly distributed
* power rests in the hands of very few
* the potential for harm and inequality is high
* the potential impact of bad actors

These are, in my view, issues of power arising from wealth inequity and not particularly related to anything technological. The difficulty is that technology amplifies the effects (as it amplifies inequities in a classroom -- this much we have learned in moving to "Digital First" pedagogies resulting from the COVID measures).

The basic principles of ethics are described as, "how we should address these issues, whilst minimising harm, ensuring morally good outcomes and fairness, and protecting human autonomy."

### Data at the heart of it
For the purposes of the course, this definition of ethics is set in the context of *data-driven innovation* which makes use of large amounts of data to train algorithms that make predictions or provide insights for decision making. Machines are increasingly now involved in the decision making too, and in taking actions. These machines are described as *intelligent*.

### Visibility of rationale
These machines include, of course, neural networks and we know from the way that these pattern-matchers work, that other than the input and output layers, it is not possible to determine the path of the rationale -- the specific choices ot selections being made in the intermediate steps -- that underlies the outputs.

### Ambient intelligent systems
Interactional moments are perceived to provide friction in the operation of systems, therefore designers are removing these for a smoother experience -- think of entering your password every time you wanted to look at your phone, now replaced with fingerprint or face recognition. The result is that such interactions become invisible to the user: it is the environment we interact with in a natural way. Unnaturally, *the environment is reading us to discern intent*.

### Human --> AI interaction
This is problematised in a video clip, suggesting that this interaction is not yet defined. I rather think that @TURING1950 had a clear enough view of what it might look like, but recent innovations have increased *system opacity* such that understanding how the system makes choices based upon how it perceives us is difficult. In some sense, we are already familiar with this idea with our less tech-savvy relatives who need support working with machines. It gets harder when you don't know there's a machine.

### Utility
Comparison with basic utilities like water, power, etc., is made from a very privileged first-world perspective: *we only notice them when they fail*. These systems were unregulated in their early days, too, and some of the horrors of human behaviour (Edison, for example) are long forgotten. As data-driven innovation moves to infect our lives by becoming a utility, the question is asked, "should it be regulated?" First steps have been made in this, of course, and we see the return of interactional friction with things like the cookie quiz on GDPR-compliant websites. The monetisation of data has led to the term, "surveillance capitalism", which describes how our identity and behaviours have become the product in a high-value industry.

### Policy lag
Clearly, policy makers are well behind the curve when it comes to data-driven innovation. GDPR and similar legislation have added friction yet advances are made at speed. The additional reading [@Hildebrandt2019] is critical of policy makers and suggests that ethics is what corporations do to avoid government interference.

