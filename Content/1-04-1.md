## Information, control and power

Formalism
: Legal choices based on logic only: what you did, and what the law is.

Realism
: Your conviction depends to a large extent on what the judge ate for breakfast.

A task is given in which students are asked to decide if building an app to influence proceedings based upon what is known from an AI analysis of jury members, is ethical. I picked the red envelope, but both answers are characterised as "incorrect" for their impact on justice. What is not presented is a choice to undo the injustice of the system itself, in which jury manipulation is permissible.

### Common ethical issues
The rapid increase in the availablility of data, particularly on consumers and their habits, has led to the rapid increase in its manipulation and exploitation, leading in turn to ethical challenges as community dependence on the systems that gather the data has produced apathy, indifference, or a sense of powerlessness in resisting it.

The very term *algorithm* has been re-purposed by social scientists to further add to the problem by obfuscating the issues as they attempt to take ownership of the matter. 

The transparency of algorithmic actions has been problematised. A new fear is whipped up about how we are being manipulated -- we are, of course, and it's our fault because we are weak, stupid or lazy. The fear of processes that are not simply understandable exacerbates the feeling of powerlessness. Explainable Artificial Intelligence, or **XAI** is a recent field that tries to push back against this fear. Why? Because that fear results in the populus avoiding participation in the behaviours that enslave them. 

> "You do look glum! What you need is a gramme of soma." [@Huxley1955].

The issue of bias in algorithms seems to be poorly understood, perhaps because of the belief of the academics that they hold some kind of moral authority to impose blind egalitarianism, or a kind a false neutrality on systems that appear to present biases. This, from the course:

> This is because they are designed by humans and trained on data generated from and by us, and therefore hold the potential to encode discrimination within decisions and predictions.

What seems to be suppressed is the possibility that the data may lead to unpalatable conclusions. There are more blacks per capita in jail because the system is racist. Other conclusions are possible, just not acceptable, and we seem to be able to bend ourselves into all kinds of shapes to avoid them.

### Consent
Consent is presented as a way to cleanse the abuse of data and hold harmless those that use it. This is difficult, of course and those who operate systems in my experience are often ignorant of consent requirements (in the use of submitted assignments to inform future students, for example), or simply ignore them in the hope that *what the eye doesn't see, the heart doesn't grieve over*. Consent doesn't work.
