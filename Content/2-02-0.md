## Crime, Justice and Technology

@Ferguson2017 describes how policing moved from a *clinical* to an *actuarial* model: from expert, individual decisions unconstrained by the parameters of a pre-designed model, to fitting people and their behaviours into categories derived from historical anaylsis. This is clearly a fundamental data mistake: to close off a model to new experience and insight is an accountant's blunder[^asimov].

Justification for the use of such tools is offered within the terms of a social contract, in which citizens surrender certain freedoms (e.g., not to kill each other -- obviously a freedom the NRA goads the rest of us to prize from its cold, dead, hands) in exchange for the benefit of protection against others who might harm us.

[^asimov]: One of my students told me today that she had started reading *Foundation* [@asimov1991foundation], which I still revere as the paradigm of modelling to which we ought to aspire. It remains as far from our clumsy, incompetent implementation of technological advances as one can imagine.

Two types of predictive policing are identified in the course:

* Predictive mapping
* Individual risk assessment programmes


### Predictive mapping

This relates data on the time and place of crimes, perhaps also with additional data on the type of crime (but not the criminal) and uses this to make a prediction or forecast of likely "hot-spots" to which police resources may be deployed in an attempt to mitigate. There are a number of reports cited for further reading but the report from Chile [@Contreras2019] is not atypical of much media coverage of the use of this kind of technology. Here's how it opens:

> El 29 de agosto de 1997, a las 2:14 AM Skynet toma conciencia de sí misma. Skynet es una inteligencia artificial que lidera el ejército de las máquinas que quieren exterminar a los humanos pues los considera una amenaza para su propia supervivencia. Skynet está basada en una red neuronal que funciona en la nube y que maneja todos los aviones y armas no tripuladas de los Estados Unidos de Norteamérica. Para eliminar a los seres humanos desata una guerra nuclear y el posterior apocalipsis.

> On August 29, 1997, at 2:14 AM Skynet becomes aware of itself. Skynet is an artificial intelligence that leads the army of machines that want to exterminate humans because it considers them a threat to its own survival. Skynet is based on a neural network that operates in the cloud and handles all the planes and unmanned weapons in the United States of America. To eliminate humans it triggers a nuclear war and subsequent apocalypse.

> -- translation by [DeepL](https://www.deepl.com/)

### Individual risk assessment programmes

Worse than that, of course, is where it gets personal: connecting *individual* with *risk assessment* is a hot potato in education, let alone policing. Perhaps because it starts with the stance that an individual person presents a risk to "us", making them implicitly "other".
